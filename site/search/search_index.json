{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"PopHealth Observatory","text":"<p>Open-source population health &amp; nutrition analytics toolkit focused initially on NHANES.</p> <p></p>"},{"location":"#features","title":"Features","text":"<ul> <li>Resilient multi-pattern XPT downloads</li> <li>Rich metadata manifest generation with filtering</li> <li>Convenience merging &amp; analytic helpers</li> <li>Streamlit exploratory app</li> <li>Versioned schema for component manifests</li> </ul>"},{"location":"#install","title":"Install","text":"<pre><code>pip install pophealth-observatory\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>from pophealth_observatory.observatory import NHANESExplorer\nexplorer = NHANESExplorer()\nmanifest = explorer.get_detailed_component_manifest(as_dataframe=True)\nprint(manifest['dataframe'].head())\n</code></pre>"},{"location":"#project-goals","title":"Project Goals","text":"<p>Provide transparent, reproducible access and lightweight analytics for national health &amp; nutrition survey data.</p>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#nhanesexplorer","title":"NHANESExplorer","text":"<p>High-level convenience class for NHANES workflows.</p>"},{"location":"api/#methods-selected","title":"Methods (selected)","text":"<ul> <li><code>get_detailed_component_manifest(...)</code></li> <li><code>save_detailed_component_manifest(path, **kwargs)</code></li> <li><code>get_demographics_data(cycle)</code></li> <li><code>get_body_measures(cycle)</code></li> <li><code>get_blood_pressure(cycle)</code></li> <li><code>create_merged_dataset(cycle)</code></li> <li><code>analyze_by_demographics(df, metric, demographic)</code></li> <li><code>create_demographic_visualization(df, metric, demographic)</code></li> <li><code>generate_summary_report(df)</code></li> </ul> <p>Refer to inline docstrings for full parameter details.</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#changelog","title":"Changelog","text":""},{"location":"changelog/#version-bump-convention-automated-via-cicd","title":"Version Bump Convention (Automated via CI/CD)","text":"<ul> <li>MAJOR (<code>x.0.0</code>): Breaking changes \u2014 commit message contains <code>[major]</code> or <code>BREAKING CHANGE</code></li> <li>MINOR (<code>0.x.0</code>): New features \u2014 commit message starts with <code>feat</code> or contains <code>[minor]</code> or <code>[feature]</code></li> <li>PATCH (<code>0.0.x</code>): Bug fixes, docs, refactoring \u2014 all other commits to main</li> <li>Automatic version tagging triggers PyPI publish via existing <code>publish.yml</code> workflow</li> </ul>"},{"location":"changelog/#021-2025-11-02","title":"[0.2.1] - 2025-11-02","text":"<p>Fixed - Constrained setuptools to <code>&lt;70.0</code> in build requirements to avoid Metadata-Version 2.4 fields that PyPI doesn't support yet (PEP 639 compatibility issue) - Enabled successful PyPI package publishing for version 0.2.1</p> <p>Added - Automated version bumping workflow (<code>.github/workflows/auto-version.yml</code>) with semantic commit message parsing</p>"},{"location":"changelog/#020-2025-09-14","title":"[0.2.0] - 2025-09-14","text":"<p>Added - Experimental RAG scaffolding (<code>pophealth_observatory.rag</code>): config, dummy embedder, sentence-transformer embedder, cosine index, pipeline orchestration, test coverage. - Optional dependency group <code>[rag]</code> with <code>sentence-transformers</code> and optional <code>faiss-cpu</code>. - README documentation for RAG usage and example code.  - Comprehensive NumPy-style docstrings added across ingestion, context, and RAG modules (documentation-only change).</p> <p>Changed - Improved pesticide analyte suggestion normalization (robust matching for names like <code>p,p'-DDE</code>). - Excluded Jupyter notebooks from Ruff lint (<code>extend-exclude</code>) temporarily to unblock CI (will refactor / clean notebooks later for compliance).</p> <p>Notes - This is an experimental feature; API may evolve before a stable 1.x release.  - Retrieval prompt truncation behavior documented (max_chars parameter in <code>_format_prompt</code>).</p>"},{"location":"changelog/#014-2025-09-14","title":"[0.1.4] - 2025-09-14","text":"<p>Added - Changelog, README badges &amp; version exposure (<code>__version__</code>). - CI enhancement plan (pending) to verify wheel install before publish.</p> <p>Changed - Lint/style conformance (wrapped long lines, import ordering, modern typing).</p>"},{"location":"changelog/#013-2025-09-14","title":"[0.1.3] - 2025-09-14","text":"<p>Changed - Version bump to capture manifest filtering and docs adjustments. - Adjusted GitHub Pages deploy condition to bypass environment protection failure.</p>"},{"location":"changelog/#012-2025-09-13","title":"[0.1.2] - 2025-09-13","text":"<p>Added - Manifest schema version &amp; generation timestamp. - Multi-URL fallback, retries, caching improvements. - Expanded component parsing &amp; filtering (year range, file types).</p> <p>Changed - Repository restructuring (apps/, manifests/, examples/, notebooks/).</p>"},{"location":"changelog/#011-2025-09-12","title":"[0.1.1] - 2025-09-12","text":"<p>Added PyPI publish automation (token-based) and lint/coverage enhancements in CI.</p>"},{"location":"changelog/#010-2025-09-12","title":"[0.1.0] - 2025-09-12","text":"<p>Initial release.</p> <p>Added: - Core <code>PopHealthObservatory</code> base class - <code>NHANESExplorer</code> subclass with demographics, body measures, blood pressure components - Caching layer for downloaded XPT files - Derived metrics (BMI categories, BP categories, averages) - Demographic stratification helper (<code>analyze_by_demographics</code>) - Visualization helper with lazy matplotlib/seaborn import - Summary report generator - Basic pytest suite - Packaging (pyproject + setup.py) and build artifacts - GitHub Actions CI (test matrix + tagged build artifacts)</p> <p>Planned (not in this release): weighted analyses, additional components, cross-cycle harmonization registry, alternative dataset adapters, DuckDB/Parquet caching, CLI interface.</p> <p>Guiding Principle: Reproducible, modular population health analytics from acquisition to insight.</p>"},{"location":"features/","title":"Feature Status","text":"<p>Comprehensive breakdown of implemented vs planned capabilities.</p>"},{"location":"features/#implemented-features","title":"\u2705 Implemented Features","text":""},{"location":"features/#data-acquisition","title":"Data Acquisition","text":"<ul> <li>Multi-URL NHANES Download: Resilient XPT file retrieval with automatic fallback patterns across CDC hosting changes</li> <li>In-Memory Caching: Session-level cache for downloaded component data (avoids redundant network calls)</li> <li>Cycle/Component Mapping: Letter suffix resolution for NHANES cycles (1999-2000 \u2192 A, 2017-2018 \u2192 J, etc.)</li> </ul>"},{"location":"features/#data-harmonization-derivation","title":"Data Harmonization &amp; Derivation","text":"<ul> <li>Demographics (DEMO): Download, column selection, semantic renaming, gender/race labels</li> <li>Body Measures (BMX): Weight, height, BMI with categorical bins (Underweight/Normal/Overweight/Obese)</li> <li>Blood Pressure (BPX): Multi-reading averages + hypertension staging (Normal/Elevated/Stage 1/Stage 2)</li> <li>Merged Datasets: Participant-level merge across DEMO, BMX, BPX via <code>participant_id</code></li> </ul>"},{"location":"features/#metadata-manifesting","title":"Metadata &amp; Manifesting","text":"<ul> <li>Component Table Parsing: Extract file listings (XPT/ZIP/FTP) from Demographics, Examination, Laboratory, Dietary, Questionnaire pages</li> <li>Schema Versioning: Manifest outputs include <code>schema_version</code> (semver) and <code>generated_at</code> (UTC ISO timestamp)</li> <li>Filtering: Year range overlap + file type subsetting</li> <li>Local Filename Derivation: Canonical naming with cycle years appended (e.g., <code>DEMO_2017_2018.xpt</code>)</li> <li>Summary Aggregation: Nested counts by component and file type</li> <li>Manifest Persistence: JSON serialization with optional flattened DataFrame attachment</li> </ul>"},{"location":"features/#analytics-helpers","title":"Analytics Helpers","text":"<ul> <li>Demographic Stratification: Group-wise descriptive stats (count, mean, median, std, min, max) for any metric by demographic variable</li> <li>Summary Report Generation: Text-based participant count, age distribution, gender/race breakdowns, health metric summaries</li> <li>Visualization: Boxplots + bar charts for metric distributions by demographic groups (lazy matplotlib/seaborn import)</li> </ul>"},{"location":"features/#pesticide-rag-scaffolding-experimental","title":"Pesticide RAG Scaffolding (Experimental)","text":"<ul> <li>Text Ingestion: Sentence segmentation, regex-based analyte/pesticide token matching, snippet window extraction</li> <li>Snippet Dataclass: Structured records (CAS RN, analyte name, parent pesticide, source ID, position, sentence window)</li> <li>JSONL Serialization: Line-oriented snippet persistence</li> <li>Analyte Reference Loading: CSV-based curated metadata (parent pesticide, metabolite class, CAS RN, PubChem CID, NHANES LOD, cycle coverage)</li> <li>Fuzzy Suggestion: Normalized substring matching for partial analyte queries</li> <li>RAG Pipeline: Load snippets \u2192 build/cache embeddings \u2192 cosine similarity retrieval \u2192 prompt assembly</li> <li>Embedder Abstraction: <code>BaseEmbedder</code> protocol with <code>DummyEmbedder</code> (deterministic hash-based) and <code>SentenceTransformerEmbedder</code> (HuggingFace models)</li> <li>Vector Index: In-memory cosine similarity with NumPy (Parquet persistence for texts/metadata)</li> <li>Generator Decoupling: Pipeline accepts external LLM callable <code>(question, snippets, prompt) -&gt; answer</code></li> </ul>"},{"location":"features/#testing-quality","title":"Testing &amp; Quality","text":"<ul> <li>Pytest Suite: 11 tests covering basic ingestion, context lookup, RAG retrieval ordering</li> <li>NumPy-Style Docstrings: Comprehensive Parameter/Returns/Raises documentation across all modules</li> <li>Lint/Format Config: Ruff + Black with notebook exclusion, 120-char line length</li> <li>CI Ready: GitHub Actions workflow scaffolds (not yet active in manifest)</li> </ul>"},{"location":"features/#documentation","title":"Documentation","text":"<ul> <li>MkDocs Site: Material theme with navigation sections</li> <li>Getting Started Guide: Installation, first manifest, Streamlit app launch</li> <li>Usage Examples: Manifest generation with filtering, quick start snippets</li> <li>API Reference: High-level method listing (inline docstrings authoritative)</li> <li>Copilot Instructions: Global, Python-specific, and R-specific (future) guidance files</li> </ul>"},{"location":"features/#applications","title":"Applications","text":"<ul> <li>Streamlit App: Interactive cycle selection, metric/demographic aggregation, manifest sampling, raw data preview</li> </ul>"},{"location":"features/#planned-features","title":"\ud83d\udd27 Planned Features","text":""},{"location":"features/#near-term-q4-2025","title":"Near-Term (Q4 2025)","text":"<ul> <li>Laboratory Panel Expansion: Lipids, glucose tolerance, inflammatory markers with dedicated loaders</li> <li>Weighted Analysis Helper: Survey design abstraction (strata, PSU, weights) for complex sample estimation</li> <li>Parquet/DuckDB Caching: Persistent local backend for multi-cycle assemblies (optional)</li> <li>CLI Utility: Command-line interface for manifest generation, data download, component listing</li> <li>Manifest Delta: Compare manifests across dates to detect new/updated files</li> </ul>"},{"location":"features/#mid-term-q1-2026","title":"Mid-Term (Q1 2026)","text":"<ul> <li>Cross-Cycle Harmonization Registry: Variable name mapping + recoding rules for longitudinal analysis</li> <li>Automated Data Dictionary Merger: Extract variable documentation from PDF/HTML component pages</li> <li>Time Trend Utilities: Multi-cycle joins with alignment &amp; weighting</li> <li>Additional Components: Dietary day 2, accelerometer, environmental exposures (dedicated loaders)</li> <li>Retention Policy: Configurable cache artifact cleanup (size/time-based)</li> </ul>"},{"location":"features/#long-term","title":"Long-Term","text":"<ul> <li>Multi-Dataset Adapters: Unified API for BRFSS, NHIS, other public health surveys</li> <li>Interactive Cohort Builder: Criteria \u2192 derived dataset manifest with provenance</li> <li>Plugin Interface: Register custom metric calculators and derivation functions</li> <li>Cloud Deployment Recipe: Serverless manifest builder + cache API</li> <li>Provenance Tracking: Content hashing, reproducibility metadata, lineage graphs</li> </ul>"},{"location":"features/#quality-tooling","title":"Quality &amp; Tooling","text":"<ul> <li>Auto API Reference: MkDocs integration with docstring extraction (partially\u2014site exists, automation pending)</li> <li>Coverage Gating: Fail CI builds below threshold</li> <li>Pre-commit Hooks: Ruff, Black, mypy (optional static typing)</li> <li>Example Notebooks Gallery: Binder/Codespaces links for interactive demos</li> </ul>"},{"location":"features/#stretch-ideas","title":"Stretch Ideas","text":"<ul> <li>Web UI: Next.js + FastAPI for manifest browsing</li> <li>ML Feature Extraction: Standardized pipelines from harmonized datasets</li> <li>Synthetic Data Generator: Teaching/demo datasets with privacy preservation</li> </ul>"},{"location":"features/#component-loader-status","title":"\ud83d\udce6 Component Loader Status","text":"Component Code Mapped Loader Method Column Harmonization Derived Metrics Demographics (DEMO) \u2705 \u2705 <code>get_demographics_data()</code> \u2705 Gender/race labels Body Measures (BMX) \u2705 \u2705 <code>get_body_measures()</code> \u2705 BMI categories Blood Pressure (BPX) \u2705 \u2705 <code>get_blood_pressure()</code> \u2705 BP staging, averages Cholesterol (TCHOL) \u2705 \u274c \u274c \u274c Diabetes (GLU) \u2705 \u274c \u274c \u274c Dietary (DR1TOT) \u2705 \u274c \u274c \u274c Physical Activity (PAQ) \u2705 \u274c \u274c \u274c Smoking (SMQ) \u2705 \u274c \u274c \u274c Alcohol (ALQ) \u2705 \u274c \u274c \u274c <p>Legend: - \u2705 Implemented - \u274c Planned (code path exists for generic download via <code>download_data()</code>, but no dedicated convenience method)</p>"},{"location":"features/#rag-pipeline-maturity","title":"\ud83e\uddea RAG Pipeline Maturity","text":"Capability Status Notes Text ingestion \u2705 Implemented Sentence segmentation, regex token matching Snippet serialization \u2705 Implemented JSONL format Reference analyte loading \u2705 Implemented CSV + YAML source registry Embedding abstraction \u2705 Implemented <code>DummyEmbedder</code> + <code>SentenceTransformerEmbedder</code> Vector index \u2705 Implemented In-memory NumPy cosine similarity Retrieval \u2705 Implemented Top-k snippet ranking Prompt assembly \u2705 Implemented Length-capped context formatting Generator integration \u2705 Implemented External callable pattern FAISS backend \ud83d\udd27 Optional Partial support via dependency marker Hybrid retrieval (lexical+vector) \ud83d\udd27 Planned BM25 + embedding fusion Streaming answers \ud83d\udd27 Planned Token-by-token generation helpers Multi-document sources \ud83d\udd27 Planned Expand beyond PDP excerpts <p>Legend: - \u2705 Implemented and tested - \ud83d\udd27 Planned or partially available</p>"},{"location":"features/#data-exchange","title":"\ud83d\uddc2\ufe0f Data Exchange","text":"Protocol Status Notes JSONL (snippets) \u2705 Implemented Text snippet artifacts JSON (manifests) \u2705 Implemented Component metadata Parquet (cross-language) \ud83d\udd27 Planned <code>shared_data/</code> directory reserved; Arrow interchange protocol documented CSV \u274c Not planned Discouraged for structured exchange Reticulate (R/Python) \u274c Prohibited Copilot instructions explicitly forbid; use Parquet"},{"location":"features/#documentation-coverage","title":"\ud83d\udcdd Documentation Coverage","text":"Artifact Status Location README \u2705 Complete <code>README.md</code> Getting Started \u2705 Complete <code>docs/getting-started.md</code> Quick Start \u2705 Complete <code>docs/usage/quickstart.md</code> Manifest Reference \u2705 Complete <code>docs/usage/manifest.md</code> API Overview \u2705 Complete <code>docs/api.md</code> Feature Status \u2705 Complete <code>docs/features.md</code> (this page) Inline Docstrings \u2705 Complete All public functions/classes (NumPy style) Copilot Instructions \u2705 Complete <code>.github/copilot-instructions.md</code>, scoped files CHANGELOG \u2705 Current <code>CHANGELOG.md</code> ROADMAP \u2705 Current <code>ROADMAP.md</code> Auto API Reference \ud83d\udd27 Planned MkDocs plugin integration pending"},{"location":"features/#continuous-integration","title":"\ud83d\udd04 Continuous Integration","text":"Step Status Notes Lint (Ruff) \ud83d\udd27 Configured <code>pyproject.toml</code> rules; CI workflow pending Format (Black) \ud83d\udd27 Configured 120-char line length; CI workflow pending Test (Pytest) \u2705 Passing 11 tests (basic, context, RAG) Coverage \ud83d\udd27 Configured <code>coverage</code> tool installed; gating not enforced Build Artifacts \ud83d\udd27 Configured <code>python -m build</code> tested locally; publish workflow pending Pre-commit Hooks \ud83d\udd27 Planned <code>.pre-commit-config.yaml</code> not yet created"},{"location":"features/#usage-readiness","title":"\ud83d\ude80 Usage Readiness","text":"Use Case Readiness Requirements Explore single-cycle demographics + anthropometrics \u2705 Production-ready Install from source or PyPI (future) Generate component file manifests with filtering \u2705 Production-ready BeautifulSoup4 optional for HTML parsing Build interactive Streamlit dashboard \u2705 Production-ready Streamlit installed Perform weighted survey analyses \u274c Not ready Helper utilities not yet implemented Cross-cycle trend analysis \u274c Not ready Harmonization registry + time utilities pending Pesticide RAG question answering \ud83e\uddea Experimental Functional but API may evolve; test coverage limited Export harmonized data for R analysis \ud83d\udd27 Partially ready Parquet protocol documented; no R source yet <p>Legend: - \u2705 Production-ready: Stable API, tested, documented - \ud83e\uddea Experimental: Functional but evolving API - \ud83d\udd27 Partially ready: Infrastructure exists, full workflow incomplete - \u274c Not ready: Planned but not implemented</p> <p>Last Updated: 2025-11-02 Version Coverage: 0.2.0</p> <p>For implementation timelines, see ROADMAP.md. For change history, see CHANGELOG.md.</p>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.8+</li> <li>pip / virtual environment recommended</li> </ul>"},{"location":"getting-started/#installation","title":"Installation","text":"<pre><code>pip install pophealth-observatory\n</code></pre> <p>From source (development):</p> <pre><code>git clone https://github.com/paulboys/PopHealth-Observatory.git\ncd PopHealth-Observatory\npip install -e .[dev,docs]\n</code></pre>"},{"location":"getting-started/#first-manifest","title":"First Manifest","text":"<pre><code>from pophealth_observatory.observatory import NHANESExplorer\nexp = NHANESExplorer()\nmanifest = exp.get_detailed_component_manifest(as_dataframe=True)\nprint(manifest['summary_counts'])\n</code></pre>"},{"location":"getting-started/#streamlit-app","title":"Streamlit App","text":"<pre><code>streamlit run apps/streamlit_app.py\n</code></pre>"},{"location":"roadmap/","title":"Roadmap","text":""},{"location":"roadmap/#near-term-q4-2025","title":"Near-Term (Q4 2025)","text":"<p>Status legend: (planned) not yet started; (in progress); (done)</p> <ul> <li>Laboratory panel ingestion expansion (lipids, glucose tolerance, inflammatory markers) (planned)</li> <li>Weighted analysis helper (survey design: strata, PSU, weights abstraction) (planned)</li> <li>Parquet/DuckDB local cache backend (optional persistent layer) (planned)</li> <li>CLI utility (<code>pophealth-observatory manifest</code> / <code>download</code> commands) (planned)</li> <li>Manifest delta generation (compare schema_version outputs across dates) (planned)</li> </ul>"},{"location":"roadmap/#mid-term-q1-2026","title":"Mid-Term (Q1 2026)","text":"<ul> <li>Cross-cycle harmonization registry (variable name mapping + recodes) (planned)</li> <li>Automated data dictionary merger (documentation extraction from PDF/HTML) (planned)</li> <li>Time trend utilities (join multiple cycles with alignment &amp; weighting) (planned)</li> <li>Additional components: dietary day 2, accelerometer, environmental exposures (planned)</li> <li>Configurable retention policy for cached artifacts (size/time-based) (planned)</li> </ul>"},{"location":"roadmap/#long-term","title":"Long-Term","text":"<ul> <li>Multi-dataset adapters (e.g., BRFSS, NHIS) under a unified acquisition API (planned)</li> <li>Interactive cohort builder (criteria -&gt; derived dataset manifest) (planned)</li> <li>Plugin interface for custom derivations (register metric calculators) (planned)</li> <li>Cloud deployment recipe (serverless manifest builder + cache API) (planned)</li> <li>Governance: provenance tracking (hashing, reproducibility metadata) (planned)</li> </ul>"},{"location":"roadmap/#quality-tooling-enhancements","title":"Quality &amp; Tooling Enhancements","text":"<ul> <li>Sphinx or MkDocs auto API reference from docstrings (partially\u2014MkDocs site exists; auto API not yet implemented) (planned)</li> <li>Coverage gating (fail under threshold) (planned)</li> <li>Pre-commit hooks (ruff, black, mypy optional) (planned)</li> <li>Example notebooks gallery (binder / codespaces link) (planned)</li> </ul>"},{"location":"roadmap/#stretch-ideas","title":"Stretch Ideas","text":"<ul> <li>Web UI (Next.js + FastAPI) for manifest browsing (planned)</li> <li>ML feature extraction pipeline from harmonized datasets (planned)</li> <li>Synthetic data generator for teaching &amp; demos (planned)</li> </ul> <p>Feedback and contributions welcome\u2014open an issue or discussion to propose adjustments.</p>"},{"location":"versioning/","title":"Automated Version Bumping &amp; Publishing","text":""},{"location":"versioning/#overview","title":"Overview","text":"<p>This repository uses automated semantic versioning via GitHub Actions. When code is pushed to <code>main</code>, the version is automatically bumped based on commit message conventions, and a new release is published to PyPI.</p>"},{"location":"versioning/#commit-message-convention","title":"Commit Message Convention","text":"<p>The version bump type is determined by your commit message:</p> Commit Message Pattern Version Bump Example Contains <code>[major]</code> or <code>BREAKING CHANGE</code> MAJOR (x.0.0) <code>feat: new API [major]</code> \u2192 0.2.1 \u2192 1.0.0 Starts with <code>feat</code> or contains <code>[minor]</code> or <code>[feature]</code> MINOR (0.x.0) <code>feat: add new loader</code> \u2192 0.2.1 \u2192 0.3.0 All other commits PATCH (0.0.x) <code>fix: typo in docstring</code> \u2192 0.2.1 \u2192 0.2.2"},{"location":"versioning/#examples","title":"Examples","text":"<pre><code># PATCH bump (0.2.1 \u2192 0.2.2)\ngit commit -m \"fix: correct BMI calculation edge case\"\ngit commit -m \"docs: update README examples\"\ngit commit -m \"refactor: simplify regex pattern\"\n\n# MINOR bump (0.2.1 \u2192 0.3.0)\ngit commit -m \"feat: add dietary intake loader\"\ngit commit -m \"feature: add export to CSV [minor]\"\n\n# MAJOR bump (0.2.1 \u2192 1.0.0)\ngit commit -m \"feat: redesign API with async support [major]\"\ngit commit -m \"BREAKING CHANGE: remove deprecated methods\"\n</code></pre>"},{"location":"versioning/#skipping-auto-version","title":"Skipping Auto-Version","text":"<p>To push changes without triggering a version bump:</p> <pre><code>git commit -m \"chore: update CI config [skip-version]\"\n</code></pre> <p>The workflow also automatically skips commits it creates (those containing \"Bump version to\").</p>"},{"location":"versioning/#workflow-details","title":"Workflow Details","text":""},{"location":"versioning/#trigger-paths","title":"Trigger Paths","text":"<p>The auto-version workflow only runs when these paths change: - <code>pophealth_observatory/**</code> (library code) - <code>tests/**</code> (test suite) - <code>pyproject.toml</code> (package metadata) - <code>requirements.txt</code> (dependencies)</p> <p>Changes to docs, notebooks, or CI configs won't trigger version bumps unless you explicitly want them to.</p>"},{"location":"versioning/#what-happens-automatically","title":"What Happens Automatically","text":"<ol> <li>Version Bump: <code>.github/workflows/auto-version.yml</code> parses your commit message</li> <li>Update pyproject.toml: Version string is updated</li> <li>Commit &amp; Push: Automated commit with message like <code>Bump version to 0.2.2 [skip-ci]</code></li> <li>Create Tag: Git tag <code>v0.2.2</code> is created and pushed</li> <li>Publish to PyPI: The tag push triggers <code>.github/workflows/publish.yml</code> which:</li> <li>Builds the wheel and source distribution</li> <li>Verifies the wheel can be imported</li> <li>Publishes to PyPI (requires <code>PYPI_API_TOKEN</code> secret)</li> <li>Deploys documentation to GitHub Pages</li> </ol>"},{"location":"versioning/#required-github-secrets","title":"Required GitHub Secrets","text":"<ul> <li><code>PYPI_API_TOKEN</code>: PyPI API token for automated publishing (already configured)</li> </ul>"},{"location":"versioning/#manual-publishing","title":"Manual Publishing","text":"<p>If you need to publish manually:</p> <pre><code># Update version in pyproject.toml\nvim pyproject.toml  # Change version = \"0.2.1\" to \"0.2.2\"\n\n# Build and publish\npython -m build\ntwine check dist/*\ntwine upload dist/*\n\n# Tag and push\ngit tag v0.2.2\ngit push origin v0.2.2\n</code></pre>"},{"location":"versioning/#version-history","title":"Version History","text":"<p>Check <code>CHANGELOG.md</code> for the full version history and release notes.</p>"},{"location":"versioning/#troubleshooting","title":"Troubleshooting","text":"<p>Q: My commit didn't trigger a version bump - Verify your commit touched one of the trigger paths - Check that the commit message doesn't contain <code>[skip-version]</code> or \"Bump version to\" - Review the Actions tab in GitHub for workflow logs</p> <p>Q: PyPI publish failed - Check that <code>PYPI_API_TOKEN</code> secret is valid - Verify the version doesn't already exist on PyPI (PyPI doesn't allow re-uploading the same version) - Review build logs for setuptools/metadata issues</p> <p>Q: I want to publish without waiting for CI - Use the manual publishing steps above - Or create a tag manually: <code>git tag v0.2.2 &amp;&amp; git push origin v0.2.2</code></p>"},{"location":"usage/manifest/","title":"Manifest Reference","text":"<p>The manifest produced by <code>get_detailed_component_manifest</code> includes:</p> Key Description schema_version Version of manifest schema generated_at UTC ISO timestamp detailed_year_records Raw grouped rows per component summary_counts Aggregated counts by component &amp; file type component_count Number of component pages processed total_file_rows Row count after filtering dataframe (optional) Flattened DataFrame if requested"},{"location":"usage/manifest/#filtering-logic","title":"Filtering Logic","text":"<ul> <li>Year range keeps rows whose interval overlaps the requested span.</li> <li>File types are matched against upper-cased set (e.g. <code>XPT</code>, <code>ZIP</code>).</li> </ul>"},{"location":"usage/manifest/#example","title":"Example","text":"<pre><code>m = exp.get_detailed_component_manifest(as_dataframe=True,\n                                        file_types=[\"XPT\"],\n                                        year_range=(\"2015\",\"2022\"))\nprint(m['total_file_rows'])\n</code></pre>"},{"location":"usage/quickstart/","title":"Quick Start","text":"<pre><code>from pophealth_observatory.observatory import NHANESExplorer\nexp = NHANESExplorer()\nmerged = exp.create_merged_dataset('2017-2018')\nprint(merged.head())\n</code></pre>"},{"location":"usage/quickstart/#generate-manifest-xpt-only-2017-2022","title":"Generate Manifest (XPT only, 2017-2022)","text":"<pre><code>manifest = exp.get_detailed_component_manifest(\n    as_dataframe=True,\n    year_range=(\"2017\",\"2022\"),\n    file_types=[\"XPT\"],\n)\nprint(manifest['summary_counts'])\n</code></pre>"}]}