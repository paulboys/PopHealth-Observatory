{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"PopHealth Observatory","text":"<p>Open-source population health &amp; nutrition analytics toolkit focused initially on NHANES.</p> <p></p>"},{"location":"#features","title":"Features","text":"<ul> <li>Resilient multi-pattern XPT downloads</li> <li>Rich metadata manifest generation with filtering</li> <li>Convenience merging &amp; analytic helpers</li> <li>Streamlit exploratory app</li> <li>Versioned schema for component manifests</li> </ul>"},{"location":"#install","title":"Install","text":"<pre><code>pip install pophealth-observatory\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>from pophealth_observatory.observatory import NHANESExplorer\nexplorer = NHANESExplorer()\nmanifest = explorer.get_detailed_component_manifest(as_dataframe=True)\nprint(manifest['dataframe'].head())\n</code></pre>"},{"location":"#project-goals","title":"Project Goals","text":"<p>Provide transparent, reproducible access and lightweight analytics for national health &amp; nutrition survey data.</p>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#nhanesexplorer","title":"NHANESExplorer","text":"<p>High-level convenience class for NHANES workflows.</p>"},{"location":"api/#methods-selected","title":"Methods (selected)","text":"<ul> <li><code>get_detailed_component_manifest(...)</code></li> <li><code>save_detailed_component_manifest(path, **kwargs)</code></li> <li><code>get_demographics_data(cycle)</code></li> <li><code>get_body_measures(cycle)</code></li> <li><code>get_blood_pressure(cycle)</code></li> <li><code>create_merged_dataset(cycle)</code></li> <li><code>analyze_by_demographics(df, metric, demographic)</code></li> <li><code>create_demographic_visualization(df, metric, demographic)</code></li> <li><code>generate_summary_report(df)</code></li> </ul> <p>Refer to inline docstrings for full parameter details.</p>"},{"location":"api/#brfssexplorer","title":"BRFSSExplorer","text":"<p>State-level health indicator access from CDC BRFSS dataset.</p>"},{"location":"api/#methods","title":"Methods","text":""},{"location":"api/#get_obesity_datayearnone","title":"<code>get_obesity_data(year=None)</code>","text":"<p>Retrieve state-level adult obesity prevalence (BMI \u2265 30).</p> <p>Parameters: - <code>year</code> (int, optional): Target year. If None, uses latest available.</p> <p>Returns: DataFrame with columns: - <code>year</code>, <code>state</code>, <code>state_name</code>, <code>value</code>, <code>low_ci</code>, <code>high_ci</code>, <code>sample_size</code>, <code>data_source</code>, <code>class_name</code>, <code>question</code></p> <p>Raises: <code>ValueError</code> if specified year not found.</p> <p>Example:</p> <pre><code>brfss = BRFSSExplorer()\nobesity_data = brfss.get_obesity_data(year=2022)\n</code></pre>"},{"location":"api/#get_indicatorclass_name-question-yearnone","title":"<code>get_indicator(class_name, question, year=None)</code>","text":"<p>Retrieve any BRFSS health indicator by class and question.</p> <p>Parameters: - <code>class_name</code> (str): BRFSS indicator class (e.g., \"Physical Activity\") - <code>question</code> (str): Exact question text from BRFSS dataset - <code>year</code> (int, optional): Target year. If None, uses latest available.</p> <p>Returns: DataFrame with same structure as <code>get_obesity_data()</code></p> <p>Raises: <code>ValueError</code> if specified year not found for this indicator.</p> <p>Example:</p> <pre><code>physical_activity = brfss.get_indicator(\n    class_name='Physical Activity',\n    question='Percent of adults aged 18 years and older who engage in no leisure-time physical activity'\n)\n</code></pre>"},{"location":"api/#list_available_indicators","title":"<code>list_available_indicators()</code>","text":"<p>List all unique class/question combinations in BRFSS dataset.</p> <p>Returns: DataFrame with columns <code>['class', 'question']</code></p> <p>Example:</p> <pre><code>indicators = brfss.list_available_indicators()\nprint(indicators[indicators['class'] == 'Obesity / Weight Status'])\n</code></pre>"},{"location":"api/#summarydf","title":"<code>summary(df)</code>","text":"<p>Generate summary statistics for a BRFSS indicator DataFrame.</p> <p>Parameters: - <code>df</code> (DataFrame): Output from <code>get_obesity_data()</code> or <code>get_indicator()</code></p> <p>Returns: dict with keys: - <code>count</code>, <code>mean_value</code>, <code>min_value</code>, <code>max_value</code>, <code>year</code>, <code>class_name</code>, <code>question</code></p> <p>Example:</p> <pre><code>obesity_data = brfss.get_obesity_data()\nstats = brfss.summary(obesity_data)\nprint(f\"Mean: {stats['mean_value']:.1f}%\")\n</code></pre>"},{"location":"api/#configuration","title":"Configuration","text":"<p>BRFSSConfig - <code>base_url</code> (str): CDC API endpoint (default: \"https://data.cdc.gov/resource/hn4x-zwk7.json\") - <code>timeout</code> (int): HTTP timeout in seconds (default: 30) - <code>default_limit</code> (int): API result limit (default: 5000)</p> <p>BRFSSExplorer constructor: - <code>config</code> (BRFSSConfig, optional): Configuration object - <code>session</code> (requests.Session, optional): Reusable HTTP session - <code>enable_cache</code> (bool): In-memory caching (default: True)</p>"},{"location":"api/#data-source","title":"Data Source","text":"<ul> <li>Dataset: CDC BRFSS Nutrition, Physical Activity, and Obesity (hn4x-zwk7)</li> <li>Documentation: https://data.cdc.gov/Nutrition-Physical-Activity-and-Obesity</li> <li>Coverage: State-level health indicators for all 50 states + DC</li> </ul> <p>See <code>docs/usage/brfss.md</code> for detailed usage examples.</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#changelog","title":"Changelog","text":""},{"location":"changelog/#version-bump-convention-automated-via-cicd","title":"Version Bump Convention (Automated via CI/CD)","text":"<ul> <li>MAJOR (<code>x.0.0</code>): Breaking changes \u2014 commit message contains <code>[major]</code> or <code>BREAKING CHANGE</code></li> <li>MINOR (<code>0.x.0</code>): New features \u2014 commit message starts with <code>feat</code> or contains <code>[minor]</code> or <code>[feature]</code></li> <li>PATCH (<code>0.0.x</code>): Bug fixes, docs, refactoring \u2014 all other commits to main</li> <li>Automatic version tagging triggers PyPI publish via existing <code>publish.yml</code> workflow</li> </ul>"},{"location":"changelog/#041-2025-11-03","title":"[0.4.1] - 2025-11-03","text":"<p>Docs - Refactored <code>SETUP_GUIDE.md</code> into concise human-focused Python setup &amp; usage guide (removed legacy Bioconductor / agent content, added validation + survey weight sections, troubleshooting, FAQ). - Updated <code>README.md</code> to surface programmatic vs analytical validation layers and experimental survey weight helpers. - Updated <code>docs/features.md</code> to: (a) remove duplicated legacy sections, (b) rephrase reticulate prohibition to planned Arrow-based R/Python interop, (c) align feature list with current capabilities.</p> <p>Added - Clear articulation of validation layers (programmatic integrity checks vs analytical reproducibility notebooks). - Survey weight helper documentation (auto weight selection + weighted mean) flagged as experimental.</p> <p>Changed - Harmonized terminology (\"Programmatic Validation\" / \"Analytical Validation\") across docs. - Navigation guidance now points users to <code>SETUP_GUIDE.md</code> for environment bootstrap.</p> <p>Notes - Version number already at 0.4.0 in <code>pyproject.toml</code>; this patch entry records documentation evolution preceding any subsequent functional changes.</p>"},{"location":"changelog/#040-2025-11-02","title":"[0.4.0] - 2025-11-02","text":"<p>Added - Programmatic validation framework: <code>validate()</code> integrating with new <code>validation.py</code> (row count checks, URL/source availability, component-level statuses) plus dataclass-backed report representation. - Survey weight helpers: <code>get_survey_weight()</code> and <code>calculate_weighted_mean()</code> for early-stage weighted analysis. - Reproducibility scaffold: <code>reproducibility/</code> directory and initial notebook for analytical validation layer. - Composite GitHub Action for Python setup (dependency install consolidation across workflows). - Documentation: validation concept sections, weighting explanation, roadmap/status updates.</p> <p>Changed - Consolidated CI workflows (lint/autofix, test matrix, publish) reducing duplication and replacing experimental reusable workflow attempt with composite action. - Enhanced README and feature docs to distinguish ingestion/harmonization vs validation responsibilities. - Strengthened multi-URL download resilience (broader pattern list, clearer diagnostics).</p> <p>Fixed - Resolved auto-version workflow failure caused by <code>sed</code> incompatibility on Windows; replaced with pure Python edit approach.</p> <p>Notes - Marks maturation from ingestion-only (0.2.x) to integrity + credibility focus (validation layers).</p>"},{"location":"changelog/#030-2025-10-15","title":"[0.3.0] - 2025-10-15","text":"<p>Added - Expanded pesticide snippet ingestion reliability (regex boundary refinements, analyte normalization improvements) preparing for RAG retrieval accuracy. - Initial analytical validation planning notes and doc placeholders (pre-implementation of full reproducibility notebook). - Streamlined manifest generation filters (year overlap + file type) aligned with forthcoming harmonization registry design.</p> <p>Changed - Refactored observatory internals for clearer separation of I/O vs transformation helpers (foundation for validation integration in 0.4.0). - Improved naming &amp; docstring consistency (NumPy style adoption near complete across public API).</p> <p>Removed - Legacy or redundant exploratory notebook code paths superseded by formalized helpers (soft deprecation documented, not breaking API).</p> <p>Notes - Transitional release laying groundwork for validation &amp; weighting; final pre-validation architectural cleanup.</p>"},{"location":"changelog/#021-2025-11-02","title":"[0.2.1] - 2025-11-02","text":"<p>Fixed - Constrained setuptools to <code>&lt;70.0</code> in build requirements to avoid Metadata-Version 2.4 fields that PyPI doesn't support yet (PEP 639 compatibility issue) - Enabled successful PyPI package publishing for version 0.2.1</p> <p>Added - Automated version bumping workflow (<code>.github/workflows/auto-version.yml</code>) with semantic commit message parsing</p>"},{"location":"changelog/#020-2025-09-14","title":"[0.2.0] - 2025-09-14","text":"<p>Added - Experimental RAG scaffolding (<code>pophealth_observatory.rag</code>): config, dummy embedder, sentence-transformer embedder, cosine index, pipeline orchestration, test coverage. - Optional dependency group <code>[rag]</code> with <code>sentence-transformers</code> and optional <code>faiss-cpu</code>. - README documentation for RAG usage and example code.  - Comprehensive NumPy-style docstrings added across ingestion, context, and RAG modules (documentation-only change).</p> <p>Changed - Improved pesticide analyte suggestion normalization (robust matching for names like <code>p,p'-DDE</code>). - Excluded Jupyter notebooks from Ruff lint (<code>extend-exclude</code>) temporarily to unblock CI (will refactor / clean notebooks later for compliance).</p> <p>Notes - This is an experimental feature; API may evolve before a stable 1.x release.  - Retrieval prompt truncation behavior documented (max_chars parameter in <code>_format_prompt</code>).</p>"},{"location":"changelog/#014-2025-09-14","title":"[0.1.4] - 2025-09-14","text":"<p>Added - Changelog, README badges &amp; version exposure (<code>__version__</code>). - CI enhancement plan (pending) to verify wheel install before publish.</p> <p>Changed - Lint/style conformance (wrapped long lines, import ordering, modern typing).</p>"},{"location":"changelog/#013-2025-09-14","title":"[0.1.3] - 2025-09-14","text":"<p>Changed - Version bump to capture manifest filtering and docs adjustments. - Adjusted GitHub Pages deploy condition to bypass environment protection failure.</p>"},{"location":"changelog/#012-2025-09-13","title":"[0.1.2] - 2025-09-13","text":"<p>Added - Manifest schema version &amp; generation timestamp. - Multi-URL fallback, retries, caching improvements. - Expanded component parsing &amp; filtering (year range, file types).</p> <p>Changed - Repository restructuring (apps/, manifests/, examples/, notebooks/).</p>"},{"location":"changelog/#011-2025-09-12","title":"[0.1.1] - 2025-09-12","text":"<p>Added PyPI publish automation (token-based) and lint/coverage enhancements in CI.</p>"},{"location":"changelog/#010-2025-09-12","title":"[0.1.0] - 2025-09-12","text":"<p>Initial release.</p> <p>Added: - Core <code>PopHealthObservatory</code> base class - <code>NHANESExplorer</code> subclass with demographics, body measures, blood pressure components - Caching layer for downloaded XPT files - Derived metrics (BMI categories, BP categories, averages) - Demographic stratification helper (<code>analyze_by_demographics</code>) - Visualization helper with lazy matplotlib/seaborn import - Summary report generator - Basic pytest suite - Packaging (pyproject + setup.py) and build artifacts - GitHub Actions CI (test matrix + tagged build artifacts)</p> <p>Planned (not in this release): weighted analyses, additional components, cross-cycle harmonization registry, alternative dataset adapters, DuckDB/Parquet caching, CLI interface.</p> <p>Guiding Principle: Reproducible, modular population health analytics from acquisition to insight.</p>"},{"location":"features/","title":"Feature Status","text":"<p>Comprehensive breakdown of implemented vs planned capabilities.</p>"},{"location":"features/#implemented-features","title":"\u2705 Implemented Features","text":""},{"location":"features/#data-acquisition","title":"Data Acquisition","text":"<ul> <li>Multi-URL NHANES Download: Resilient XPT file retrieval with automatic fallback patterns across CDC hosting changes</li> <li>In-Memory Caching: Session-level cache for downloaded component data (avoids redundant network calls)</li> <li>Cycle/Component Mapping: Letter suffix resolution for NHANES cycles (1999-2000 \u2192 A, 2017-2018 \u2192 J, etc.)</li> </ul>"},{"location":"features/#data-harmonization-derivation","title":"Data Harmonization &amp; Derivation","text":"<ul> <li>Demographics (DEMO): Download, column selection, semantic renaming, gender/race labels</li> <li>Body Measures (BMX): Weight, height, BMI with categorical bins (Underweight/Normal/Overweight/Obese)</li> <li>Blood Pressure (BPX): Multi-reading averages + hypertension staging (Normal/Elevated/Stage 1/Stage 2)</li> <li>Merged Datasets: Participant-level merge across DEMO, BMX, BPX via <code>participant_id</code></li> </ul>"},{"location":"features/#metadata-manifesting","title":"Metadata &amp; Manifesting","text":"<ul> <li>Component Table Parsing: Extract file listings (XPT/ZIP/FTP) from Demographics, Examination, Laboratory, Dietary, Questionnaire pages</li> <li>Schema Versioning: Manifest outputs include <code>schema_version</code> (semver) and <code>generated_at</code> (UTC ISO timestamp)</li> <li>Filtering: Year range overlap + file type subsetting</li> <li>Local Filename Derivation: Canonical naming with cycle years appended (e.g., <code>DEMO_2017_2018.xpt</code>)</li> <li>Summary Aggregation: Nested counts by component and file type</li> <li>Manifest Persistence: JSON serialization with optional flattened DataFrame attachment</li> </ul>"},{"location":"features/#analytics-helpers","title":"Analytics Helpers","text":"<ul> <li>Demographic Stratification: Group-wise descriptive stats (count, mean, median, std, min, max) for any metric by demographic variable</li> <li>Summary Report Generation: Text-based participant count, age distribution, gender/race breakdowns, health metric summaries</li> <li>Visualization: Boxplots + bar charts for metric distributions by demographic groups (lazy matplotlib/seaborn import)</li> <li>Survey Weight Support: Helper methods to identify correct survey weights (<code>get_survey_weight</code>) and calculate weighted means (<code>calculate_weighted_mean</code>)</li> </ul>"},{"location":"features/#testing-quality","title":"Testing &amp; Quality","text":"<ul> <li>Programmatic Validation: <code>validate()</code> method to verify data integrity against official CDC metadata (URL correctness, row counts)</li> <li>Analytical Validation Framework: Reproducibility notebooks to validate tool output against published research (<code>reproducibility/</code>)</li> <li>Pytest Suite: 18 tests covering basic ingestion, context lookup, RAG retrieval, and validation module structure</li> <li>NumPy-Style Docstrings: Comprehensive Parameter/Returns/Raises documentation across all modules</li> <li>Lint/Format Config: Ruff + Black with notebook exclusion, 120-char line length</li> <li>Pre-commit Hooks: Automated code formatting and linting with Black, Ruff, and file hygiene checks</li> </ul>"},{"location":"features/#documentation","title":"Documentation","text":"<ul> <li>MkDocs Site: Material theme with navigation sections</li> <li>Getting Started Guide: Installation, first manifest, Streamlit app launch</li> <li>Usage Examples: Manifest generation, quick start snippets, data validation guide</li> <li>API Reference: High-level method listing (inline docstrings authoritative)</li> <li>Copilot Instructions: Global, Python-specific, and R-specific (future) guidance files</li> </ul>"},{"location":"features/#applications","title":"Applications","text":"<ul> <li>Streamlit App: Interactive cycle selection, metric/demographic aggregation, manifest sampling, raw data preview</li> <li>Reproducibility Notebooks: Executable studies that validate tool correctness against published statistics</li> </ul>"},{"location":"features/#planned-features","title":"\ud83d\udd27 Planned Features","text":""},{"location":"features/#near-term-q4-2025","title":"Near-Term (Q4 2025)","text":"<ul> <li>Laboratory Panel Expansion: Lipids, glucose tolerance, inflammatory markers with dedicated loaders</li> <li>Parquet/DuckDB Caching: Persistent local backend for multi-cycle assemblies (optional)</li> <li>CLI Utility: Command-line interface for manifest generation, data download, component listing</li> <li>Manifest Delta: Compare manifests across dates to detect new/updated files</li> </ul>"},{"location":"features/#mid-term-q1-2026","title":"Mid-Term (Q1 2026)","text":"<ul> <li>Cross-Cycle Harmonization Registry: Variable name mapping + recoding rules for longitudinal analysis</li> <li>Automated Data Dictionary Merger: Extract variable documentation from PDF/HTML component pages</li> <li>Time Trend Utilities: Multi-cycle joins with alignment &amp; weighting</li> <li>Additional Components: Dietary day 2, accelerometer, environmental exposures (dedicated loaders)</li> <li>Retention Policy: Configurable cache artifact cleanup (size/time-based)</li> </ul>"},{"location":"features/#long-term","title":"Long-Term","text":"<ul> <li>Multi-Dataset Adapters: Unified API for BRFSS, NHIS, other public health surveys</li> <li>Interactive Cohort Builder: Criteria \u2192 derived dataset manifest with provenance</li> <li>Plugin Interface: Register custom metric calculators and derivation functions</li> <li>Cloud Deployment Recipe: Serverless manifest builder + cache API</li> <li>Provenance Tracking: Content hashing, reproducibility metadata, lineage graphs</li> </ul>"},{"location":"features/#quality-tooling","title":"Quality &amp; Tooling","text":"<ul> <li>Auto API Reference: MkDocs integration with docstring extraction (partially\u2014site exists, automation pending)</li> <li>Coverage Gating: Fail CI builds below threshold</li> <li>Example Notebooks Gallery: Binder/Codespaces links for interactive demos</li> </ul>"},{"location":"features/#stretch-ideas","title":"Stretch Ideas","text":"<ul> <li>Web UI: Next.js + FastAPI for manifest browsing</li> <li>ML Feature Extraction: Standardized pipelines from harmonized datasets</li> <li>Synthetic Data Generator: Teaching/demo datasets with privacy preservation</li> </ul>"},{"location":"features/#component-loader-status","title":"\ud83d\udce6 Component Loader Status","text":"Component Code Mapped Loader Method Column Harmonization Derived Metrics Demographics (DEMO) \u2705 \u2705 <code>get_demographics_data()</code> \u2705 Gender/race labels, survey weights Body Measures (BMX) \u2705 \u2705 <code>get_body_measures()</code> \u2705 BMI categories Blood Pressure (BPX) \u2705 \u2705 <code>get_blood_pressure()</code> \u2705 BP staging, averages Cholesterol (TCHOL) \u2705 \u274c \u274c \u274c Diabetes (GLU) \u2705 \u274c \u274c \u274c Dietary (DR1TOT) \u2705 \u274c \u274c \u274c Physical Activity (PAQ) \u2705 \u274c \u274c \u274c Smoking (SMQ) \u2705 \u274c \u274c \u274c Alcohol (ALQ) \u2705 \u274c \u274c \u274c <p>Legend: - \u2705 Implemented - \u274c Planned (code path exists for generic download via <code>download_data()</code>, but no dedicated convenience method)</p>"},{"location":"features/#rag-pipeline-maturity","title":"\ud83e\uddea RAG Pipeline Maturity","text":"Capability Status Notes Text ingestion \u2705 Implemented Sentence segmentation, regex token matching Snippet serialization \u2705 Implemented JSONL format Reference analyte loading \u2705 Implemented CSV + YAML source registry Embedding abstraction \u2705 Implemented <code>DummyEmbedder</code> + <code>SentenceTransformerEmbedder</code> Vector index \u2705 Implemented In-memory NumPy cosine similarity Retrieval \u2705 Implemented Top-k snippet ranking Prompt assembly \u2705 Implemented Length-capped context formatting Generator integration \u2705 Implemented External callable pattern FAISS backend \ud83d\udd27 Optional Partial support via dependency marker Hybrid retrieval (lexical+vector) \ud83d\udd27 Planned BM25 + embedding fusion Streaming answers \ud83d\udd27 Planned Token-by-token generation helpers Multi-document sources \ud83d\udd27 Planned Expand beyond PDP excerpts <p>Legend: - \u2705 Implemented and tested - \ud83d\udd27 Planned or partially available</p>"},{"location":"features/#data-exchange","title":"\ud83d\uddc2\ufe0f Data Exchange","text":"Protocol Status Notes JSONL (snippets) \u2705 Implemented Text snippet artifacts JSON (manifests) \u2705 Implemented Component metadata Parquet (cross-language) \ud83d\udd27 Planned <code>shared_data/</code> directory reserved; Arrow interchange protocol documented CSV \u274c Not planned Discouraged for structured exchange R/Python Interop (Arrow) \ud83d\udd27 Planned Future parquet-based exchange; no reticulate bridging"},{"location":"features/#documentation-coverage","title":"\ud83d\udcdd Documentation Coverage","text":"Artifact Status Location README \u2705 Complete <code>README.md</code> Getting Started \u2705 Complete <code>docs/getting-started.md</code> Quick Start \u2705 Complete <code>docs/usage/quickstart.md</code> Data Validation Guide \u2705 Complete <code>docs/usage/validation.md</code> Manifest Reference \u2705 Complete <code>docs/usage/manifest.md</code> API Overview \u2705 Complete <code>docs/api.md</code> Feature Status \u2705 Complete <code>docs/features.md</code> (this page) Inline Docstrings \u2705 Complete All public functions/classes (NumPy style) Copilot Instructions \u2705 Complete <code>.github/copilot-instructions.md</code>, scoped files CHANGELOG \u2705 Current <code>CHANGELOG.md</code> ROADMAP \u2705 Current <code>ROADMAP.md</code> Auto API Reference \ud83d\udd27 Planned MkDocs plugin integration pending"},{"location":"features/#continuous-integration","title":"\ud83d\udd04 Continuous Integration","text":"Step Status Notes Lint (Ruff) \u2705 Implemented Via pre-commit hooks and <code>autofix-pr</code> workflow Format (Black) \u2705 Implemented Via pre-commit hooks and <code>autofix-pr</code> workflow Test (Pytest) \u2705 Passing 18 tests (basic, context, RAG, validation) Coverage \ud83d\udd27 Configured <code>coverage</code> tool installed; gating not enforced Build Artifacts \u2705 Implemented <code>publish.yml</code> workflow handles build/publish Pre-commit Hooks \u2705 Implemented <code>.pre-commit-config.yaml</code> with Black, Ruff, etc. Auto-Versioning \u2705 Implemented <code>auto-version.yml</code> bumps version on merge to main"},{"location":"features/#usage-readiness","title":"\ud83d\ude80 Usage Readiness","text":"Use Case Readiness Requirements Explore single-cycle demographics + anthropometrics \u2705 Production-ready Install from source or PyPI Generate component file manifests with filtering \u2705 Production-ready BeautifulSoup4 optional for HTML parsing Build interactive Streamlit dashboard \u2705 Production-ready Streamlit installed Perform weighted survey analyses \ud83e\uddea Experimental Helper methods implemented; complex variance not yet supported Cross-cycle trend analysis \u274c Not ready Harmonization registry + time utilities pending Pesticide RAG question answering \ud83e\uddea Experimental Functional but API may evolve; test coverage limited Export harmonized data for R analysis \ud83d\udd27 Partially ready Parquet protocol documented; no R source yet <p>Legend: - \u2705 Production-ready: Stable API, tested, documented - \ud83e\uddea Experimental: Functional but evolving API - \ud83d\udd27 Partially ready: Infrastructure exists, full workflow incomplete - \u274c Not ready: Planned but not implemented</p> <p>Last Updated: 2025-11-03 Version Coverage: 0.4.0</p> <p>For implementation timelines, see ROADMAP.md. For change history, see CHANGELOG.md.</p>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.8+</li> <li>pip / virtual environment recommended</li> </ul>"},{"location":"getting-started/#installation","title":"Installation","text":"<pre><code>pip install pophealth-observatory\n</code></pre> <p>From source (development):</p> <pre><code>git clone https://github.com/paulboys/PopHealth-Observatory.git\ncd PopHealth-Observatory\npip install -e .[dev,docs]\n</code></pre>"},{"location":"getting-started/#first-manifest","title":"First Manifest","text":"<pre><code>from pophealth_observatory.observatory import NHANESExplorer\nexp = NHANESExplorer()\nmanifest = exp.get_detailed_component_manifest(as_dataframe=True)\nprint(manifest['summary_counts'])\n</code></pre>"},{"location":"getting-started/#streamlit-app","title":"Streamlit App","text":"<pre><code>streamlit run apps/streamlit_app.py\n</code></pre>"},{"location":"license/","title":"License","text":"<p>PopHealth Observatory is released under the MIT License.</p>"},{"location":"license/#mit-license","title":"MIT License","text":"<p>Copyright (c) 2025 Paul Boys and PopHealth Observatory contributors</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p> <p>GitHub Repository License File: View LICENSE on GitHub</p>"},{"location":"pre-commit/","title":"Pre-commit Setup","text":"<p>This project uses pre-commit to enforce code quality checks before commits.</p>"},{"location":"pre-commit/#installation","title":"Installation","text":"<p>After cloning the repository and setting up your virtual environment:</p> <pre><code># Install development dependencies (includes pre-commit)\npip install -e .[dev]\n\n# Install the pre-commit hooks\npre-commit install\n</code></pre>"},{"location":"pre-commit/#what-gets-checked","title":"What Gets Checked","text":"<p>The pre-commit hooks automatically run:</p> <ol> <li>Black - Code formatting (Python 3.10+ style, 120 char line length)</li> <li>Ruff - Fast Python linter with auto-fixes</li> <li>Trailing whitespace - Remove trailing spaces</li> <li>End of file fixer - Ensure files end with newline</li> <li>YAML syntax - Validate YAML files</li> <li>Large files - Prevent commits of files &gt;2MB</li> <li>Merge conflicts - Detect unresolved merge markers</li> <li>Line endings - Normalize to LF</li> </ol>"},{"location":"pre-commit/#usage","title":"Usage","text":""},{"location":"pre-commit/#automatic-recommended","title":"Automatic (Recommended)","text":"<p>Once installed, hooks run automatically on <code>git commit</code>. If any check fails, the commit is blocked and issues are reported.</p> <pre><code>git add .\ngit commit -m \"feat: add new feature\"\n# Hooks run automatically\n</code></pre>"},{"location":"pre-commit/#manual-run","title":"Manual Run","text":"<p>Run checks on all files without committing:</p> <pre><code># Check all files\npre-commit run --all-files\n\n# Check specific files\npre-commit run --files path/to/file.py\n</code></pre>"},{"location":"pre-commit/#bypassing-hooks-use-sparingly","title":"Bypassing Hooks (Use Sparingly)","text":"<p>In rare cases where you need to commit without running hooks:</p> <pre><code>git commit --no-verify -m \"emergency fix\"\n</code></pre> <p>\u26a0\ufe0f Warning: Bypassing hooks may cause CI failures. Use only when necessary.</p>"},{"location":"pre-commit/#updating-hooks","title":"Updating Hooks","text":"<p>Pre-commit hooks are versioned in <code>.pre-commit-config.yaml</code>. To update to latest versions:</p> <pre><code>pre-commit autoupdate\n</code></pre>"},{"location":"pre-commit/#troubleshooting","title":"Troubleshooting","text":""},{"location":"pre-commit/#hooks-not-running","title":"Hooks not running","text":"<pre><code># Reinstall hooks\npre-commit uninstall\npre-commit install\n</code></pre>"},{"location":"pre-commit/#clear-hook-cache","title":"Clear hook cache","text":"<pre><code>pre-commit clean\npre-commit install --install-hooks\n</code></pre>"},{"location":"pre-commit/#skip-specific-hooks","title":"Skip specific hooks","text":"<p>Add to commit message or set environment variable:</p> <pre><code># Skip a specific hook\nSKIP=black git commit -m \"message\"\n\n# Skip all hooks (same as --no-verify)\nSKIP=all git commit -m \"message\"\n</code></pre>"},{"location":"pre-commit/#ci-integration","title":"CI Integration","text":"<p>The same checks run in GitHub Actions CI (<code>ci.yml</code>), so passing pre-commit locally ensures CI will pass.</p>"},{"location":"pre-commit/#configuration","title":"Configuration","text":"<p>Pre-commit configuration is in <code>.pre-commit-config.yaml</code>: - Hook versions are pinned for reproducibility - Notebooks and site directories are excluded - Black/Ruff settings match <code>pyproject.toml</code> configuration</p> <p>For more details, see: https://pre-commit.com/</p>"},{"location":"roadmap/","title":"Roadmap","text":""},{"location":"roadmap/#near-term-q4-2025","title":"Near-Term (Q4 2025)","text":"<p>Status legend: (planned) not yet started; (in progress); (done)</p> <ul> <li>Programmatic Data Validation: Implement <code>validate()</code> method to check data integrity against CDC metadata.</li> <li>Analytical Validation Framework: Establish a process and tools (<code>reproducibility/</code>) to validate against published research.</li> <li>Survey-Weighted Analysis Helpers: Add helpers for <code>get_survey_weight()</code> and <code>calculate_weighted_mean()</code>.</li> <li>Pre-commit Hooks: Integrate automated linting and formatting.</li> <li>Laboratory Panel Expansion: Add dedicated loaders for lipids, glucose, and other common lab panels.</li> <li>Parquet/DuckDB Caching: Introduce an optional, persistent local cache for large, multi-cycle datasets.</li> <li>CLI Utility: Create a command-line interface for core functions like manifest generation and data downloads.</li> <li>Manifest delta generation (compare schema_version outputs across dates) (planned)</li> </ul>"},{"location":"roadmap/#mid-term-q1-2026","title":"Mid-Term (Q1 2026)","text":"<ul> <li>Cross-cycle harmonization registry (variable name mapping + recodes) (planned)</li> <li>Automated data dictionary merger (documentation extraction from PDF/HTML) (planned)</li> <li>Time trend utilities (join multiple cycles with alignment &amp; weighting) (planned)</li> <li>Additional components: dietary day 2, accelerometer, environmental exposures (planned)</li> <li>Configurable retention policy for cached artifacts (size/time-based) (planned)</li> </ul>"},{"location":"roadmap/#long-term","title":"Long-Term","text":"<ul> <li>Multi-dataset adapters (e.g., BRFSS, NHIS) under a unified acquisition API (planned)</li> <li>Interactive cohort builder (criteria -&gt; derived dataset manifest) (planned)</li> <li>Plugin interface for custom derivations (register metric calculators) (planned)</li> <li>Cloud deployment recipe (serverless manifest builder + cache API) (planned)</li> <li>Governance: provenance tracking (hashing, reproducibility metadata) (planned)</li> </ul>"},{"location":"roadmap/#quality-tooling-enhancements","title":"Quality &amp; Tooling Enhancements","text":"<ul> <li>Sphinx or MkDocs auto API reference from docstrings (partially\u2014MkDocs site exists; auto API not yet implemented) (planned)</li> <li>Coverage gating (fail under threshold) (planned)</li> <li>Pre-commit hooks (ruff, black, mypy optional) (planned)</li> <li>Example notebooks gallery (binder / codespaces link) (planned)</li> </ul>"},{"location":"roadmap/#stretch-ideas","title":"Stretch Ideas","text":"<ul> <li>Web UI (Next.js + FastAPI) for manifest browsing (planned)</li> <li>ML feature extraction pipeline from harmonized datasets (planned)</li> <li>Synthetic data generator for teaching &amp; demos (planned)</li> </ul> <p>Feedback and contributions welcome\u2014open an issue or discussion to propose adjustments.</p>"},{"location":"setup-guide/","title":"PopHealth Observatory \u2013 Setup &amp; Usage Guide","text":"<p>(Synced from root <code>SETUP_GUIDE.md</code> \u2013 do not edit this file directly. Update the root file and re-run sync.)</p> <p>Human-facing setup instructions for using the Python toolkit. Internal agent / generation rules live in <code>.github/copilot-instructions.md</code> and are intentionally excluded here.</p>"},{"location":"setup-guide/#1-prerequisites","title":"1. Prerequisites","text":"Requirement Notes Python 3.10+ Tested on 3.11 / 3.12 Git For cloning + version control Optional: virtual env <code>python -m venv .venv</code> or <code>conda create -n pophealth python=3.11</code> Optional: Streamlit For the interactive app (<code>pip install streamlit</code>) <p>R is not required. A future optional R layer will use Apache Arrow for file interchange (no Python\u2013R bridging needed).</p>"},{"location":"setup-guide/#2-install","title":"2. Install","text":"<pre><code>git clone https://github.com/paulboys/PopHealth-Observatory.git\ncd PopHealth-Observatory\npython -m venv .venv\n./.venv/Scripts/Activate.ps1  # Windows PowerShell\npip install -e .[dev]\n</code></pre> <p>Minimal verification:</p> <pre><code>pytest -q\npython -c \"import pophealth_observatory as p; print(p.__version__)\"\n</code></pre>"},{"location":"setup-guide/#3-core-workflow","title":"3. Core Workflow","text":"<pre><code>from pophealth_observatory.observatory import NHANESExplorer\n\nexplorer = NHANESExplorer()\n\n# Download &amp; merge demographics, body measures, and blood pressure\n# Note: create_merged_dataset() currently merges all three components by default\ndf = explorer.create_merged_dataset(cycle=\"2017-2018\")\n\n# Validate integrity against CDC metadata\nreport = explorer.validate(cycle=\"2017-2018\", components=[\"demographics\", \"body_measures\", \"blood_pressure\"])\nprint(f\"Validation status: {report['status']}\")\n\n# Weighted mean (experimental survey helper - auto-detects survey weights)\nresult = explorer.calculate_weighted_mean(df, variable=\"body_mass_index\")\nprint(f\"Weighted BMI mean: {result['weighted_mean']:.2f}\")\n</code></pre>"},{"location":"setup-guide/#4-key-concepts","title":"4. Key Concepts","text":"Concept Description Output Ingestion Robust multi-URL NHANES file download DataFrames Harmonization Column selection + semantic renaming + derived metrics Standardized schema Manifest Structured inventory of component listing tables JSON / DataFrame Validation Row count &amp; source checks for integrity Report object Pesticide snippets Regex-based analyte sentence windows JSONL lines RAG (experimental) Embedding + similarity retrieval of snippet context Ranked snippet dicts"},{"location":"setup-guide/#5-data-outputs-locations","title":"5. Data Outputs &amp; Locations","text":"Artifact Path Format Manifest JSON <code>manifests/</code> <code>.json</code> Pesticide snippets <code>data/processed/pesticides/</code> <code>.jsonl</code> Reference tables <code>data/reference/</code> <code>.csv</code> / <code>.yml</code> Raw pesticide text <code>data/raw/pesticides/</code> <code>.txt</code> <p>Parquet caching for large multi-cycle merges is planned (will locate under a future <code>shared_data/</code> or <code>data/processed/</code> subdirectory with date-stamped filenames).</p>"},{"location":"setup-guide/#6-validation-strategy","title":"6. Validation Strategy","text":"<ol> <li>Programmatic: <code>validate()</code> compares ingested data vs. CDC published metadata (rows, availability).</li> <li>Analytical (in progress): <code>reproducibility/</code> notebooks re-derive published aggregate stats to confirm end-to-end correctness.</li> </ol> <p>Edge cases handled: missing downloads \u2192 empty DataFrame; mismatch in participant IDs triggers warning; missing expected columns raise <code>ValueError</code>.</p>"},{"location":"setup-guide/#7-survey-weights-experimental-helpers","title":"7. Survey Weights (Experimental Helpers)","text":"<p>Functions:</p> <pre><code>explorer.get_survey_weight(cycle: str, component: str) -&gt; str\nexplorer.calculate_weighted_mean(data: pd.DataFrame, variable: str, weight_var: str = None, min_weight: float = 0) -&gt; dict\n</code></pre> <p>The <code>calculate_weighted_mean</code> function auto-detects survey weights (exam_weight, interview_weight, or dietary_day1_weight) if not specified. Returns a dictionary with <code>weighted_mean</code>, <code>unweighted_mean</code>, <code>n_obs</code>, and <code>sum_weights</code>.</p> <p>Currently covers standard 2-year weights. Planned: variance estimation &amp; multi-cycle normalized weighting.</p>"},{"location":"setup-guide/#8-development-tasks","title":"8. Development Tasks","text":"<pre><code># Lint &amp; format\nruff check .\nblack --check .\n\n# Tests &amp; coverage\npytest -q\ncoverage run -m pytest &amp;&amp; coverage report -m\n\n# Build docs\nmkdocs build\n</code></pre> <p>Install/update pre-commit hooks:</p> <pre><code>pre-commit install\npre-commit run --all-files\n</code></pre>"},{"location":"setup-guide/#9-contributing","title":"9. Contributing","text":"<ol> <li>Open an issue describing feature/bug.</li> <li>Create a branch (<code>feat/&lt;short&gt;</code> or <code>fix/&lt;short&gt;</code>).</li> <li>Add type hints &amp; NumPy-style docstrings for new public functions.</li> <li>Add tests (use <code>tmp_path</code> for filesystem side-effects). Focus on deterministic helpers.</li> <li>Update <code>CHANGELOG.md</code> for user-facing changes.</li> <li>Ensure CI passes before requesting review.</li> </ol>"},{"location":"setup-guide/#10-planned-r-layer-future","title":"10. Planned R Layer (Future)","text":"<p>The R layer will: parse harmonized parquet outputs via <code>arrow</code>, produce advanced survey or longitudinal analyses, and optionally write derived metrics back to shared parquet. There is no S4 implementation yet; ignore any historical Bioconductor references found in older commits.</p>"},{"location":"setup-guide/#11-faq","title":"11. FAQ","text":"Question Answer Do I need R? No\u2014pure Python usage today. Why JSONL for snippets? Efficient line-wise streaming &amp; indexing. How do I regenerate a manifest? Use <code>get_detailed_component_manifest</code> or <code>save_detailed_component_manifest</code>. Can I add new analyte domains? Follow the pattern in <code>pesticide_ingestion.py</code> (compile regex once, yield dataclass instances). How do I trust weights? Helpers are early-stage; cross-check with NHANES analytic guidance."},{"location":"setup-guide/#12-troubleshooting-quick-reference","title":"12. Troubleshooting Quick Reference","text":"Symptom Likely Cause Action Empty DataFrame All URL attempts failed Re-run with network available; inspect cycle code Validation mismatch Source metadata changed Open issue; update scraper logic No snippet matches Patterns too strict Inspect reference file; broaden regex tokens Slow merge Large multi-cycle join Future caching; consider subset of cycles"},{"location":"setup-guide/#13-ethical-usage-notes","title":"13. Ethical / Usage Notes","text":"<p>Not a clinical decision tool. Verify methodology when publishing. Cite NHANES appropriately.</p>"},{"location":"setup-guide/#14-next-milestones","title":"14. Next Milestones","text":"<p>See <code>ROADMAP.md</code> for: harmonization registry, time trend utilities, caching backend, coverage gating.</p>"},{"location":"setup-guide/#15-license","title":"15. License","text":"<p>MIT License \u2013 see the LICENSE file on GitHub or the in-site copy on the License page.</p> <p>Last updated: 2025-11-03</p> <p>Last sync (source mtime): 2025-11-04 10:04 UTC</p>"},{"location":"versioning/","title":"Automated Version Bumping &amp; Publishing","text":""},{"location":"versioning/#overview","title":"Overview","text":"<p>This repository uses automated semantic versioning via GitHub Actions. When code is pushed to <code>main</code>, the version is automatically bumped based on commit message conventions, and a new release is published to PyPI.</p>"},{"location":"versioning/#commit-message-convention","title":"Commit Message Convention","text":"<p>The version bump type is determined by your commit message:</p> Commit Message Pattern Version Bump Example Contains <code>[major]</code> or <code>BREAKING CHANGE</code> MAJOR (x.0.0) <code>feat: new API [major]</code> \u2192 0.2.1 \u2192 1.0.0 Starts with <code>feat</code> or contains <code>[minor]</code> or <code>[feature]</code> MINOR (0.x.0) <code>feat: add new loader</code> \u2192 0.2.1 \u2192 0.3.0 All other commits PATCH (0.0.x) <code>fix: typo in docstring</code> \u2192 0.2.1 \u2192 0.2.2"},{"location":"versioning/#examples","title":"Examples","text":"<pre><code># PATCH bump (0.2.1 \u2192 0.2.2)\ngit commit -m \"fix: correct BMI calculation edge case\"\ngit commit -m \"docs: update README examples\"\ngit commit -m \"refactor: simplify regex pattern\"\n\n# MINOR bump (0.2.1 \u2192 0.3.0)\ngit commit -m \"feat: add dietary intake loader\"\ngit commit -m \"feature: add export to CSV [minor]\"\n\n# MAJOR bump (0.2.1 \u2192 1.0.0)\ngit commit -m \"feat: redesign API with async support [major]\"\ngit commit -m \"BREAKING CHANGE: remove deprecated methods\"\n</code></pre>"},{"location":"versioning/#skipping-auto-version","title":"Skipping Auto-Version","text":"<p>To push changes without triggering a version bump:</p> <pre><code>git commit -m \"chore: update CI config [skip-version]\"\n</code></pre> <p>The workflow also automatically skips commits it creates (those containing \"Bump version to\").</p>"},{"location":"versioning/#workflow-details","title":"Workflow Details","text":""},{"location":"versioning/#trigger-paths","title":"Trigger Paths","text":"<p>The auto-version workflow only runs when these paths change: - <code>pophealth_observatory/**</code> (library code) - <code>tests/**</code> (test suite) - <code>pyproject.toml</code> (package metadata) - <code>requirements.txt</code> (dependencies)</p> <p>Changes to docs, notebooks, or CI configs won't trigger version bumps unless you explicitly want them to.</p>"},{"location":"versioning/#what-happens-automatically","title":"What Happens Automatically","text":"<ol> <li>Version Bump: <code>.github/workflows/auto-version.yml</code> parses your commit message</li> <li>Update pyproject.toml: Version string is updated</li> <li>Commit &amp; Push: Automated commit with message like <code>Bump version to 0.2.2 [skip-ci]</code></li> <li>Create Tag: Git tag <code>v0.2.2</code> is created and pushed</li> <li>Publish to PyPI: The tag push triggers <code>.github/workflows/publish.yml</code> which:</li> <li>Builds the wheel and source distribution</li> <li>Verifies the wheel can be imported</li> <li>Publishes to PyPI (requires <code>PYPI_API_TOKEN</code> secret)</li> <li>Deploys documentation to GitHub Pages</li> </ol>"},{"location":"versioning/#required-github-secrets","title":"Required GitHub Secrets","text":"<ul> <li><code>PYPI_API_TOKEN</code>: PyPI API token for automated publishing (already configured)</li> </ul>"},{"location":"versioning/#manual-publishing","title":"Manual Publishing","text":"<p>If you need to publish manually:</p> <pre><code># Update version in pyproject.toml\nvim pyproject.toml  # Change version = \"0.2.1\" to \"0.2.2\"\n\n# Build and publish\npython -m build\ntwine check dist/*\ntwine upload dist/*\n\n# Tag and push\ngit tag v0.2.2\ngit push origin v0.2.2\n</code></pre>"},{"location":"versioning/#version-history","title":"Version History","text":"<p>Check <code>CHANGELOG.md</code> for the full version history and release notes.</p>"},{"location":"versioning/#troubleshooting","title":"Troubleshooting","text":"<p>Q: My commit didn't trigger a version bump - Verify your commit touched one of the trigger paths - Check that the commit message doesn't contain <code>[skip-version]</code> or \"Bump version to\" - Review the Actions tab in GitHub for workflow logs</p> <p>Q: PyPI publish failed - Check that <code>PYPI_API_TOKEN</code> secret is valid - Verify the version doesn't already exist on PyPI (PyPI doesn't allow re-uploading the same version) - Review build logs for setuptools/metadata issues</p> <p>Q: I want to publish without waiting for CI - Use the manual publishing steps above - Or create a tag manually: <code>git tag v0.2.2 &amp;&amp; git push origin v0.2.2</code></p>"},{"location":"usage/brfss/","title":"BRFSS Integration","text":"<p>The <code>BRFSSExplorer</code> class provides access to state-level health indicators from the CDC's Behavioral Risk Factor Surveillance System (BRFSS) dataset. This complements NHANES national-level data with geographic health metrics.</p>"},{"location":"usage/brfss/#why-brfss","title":"Why BRFSS?","text":"<p>NHANES provides detailed clinical measurements and demographics but deliberately omits geographic identifiers (state, county) from public datasets due to privacy constraints. Small sample sizes combined with demographic details could enable participant re-identification.</p> <p>BRFSS fills this gap by providing state-level prevalence estimates for similar health metrics. While BRFSS lacks the clinical depth of NHANES (no blood samples, physical examinations), it offers:</p> <ul> <li>State-level geographic granularity</li> <li>Larger sample sizes per state</li> <li>Consistent annual data collection</li> <li>Complementary health behaviors (diet, physical activity, screening rates)</li> </ul>"},{"location":"usage/brfss/#quick-start","title":"Quick Start","text":""},{"location":"usage/brfss/#basic-obesity-data","title":"Basic Obesity Data","text":"<pre><code>from pophealth_observatory import BRFSSExplorer\n\n# Initialize explorer\nbrfss = BRFSSExplorer()\n\n# Get latest obesity data for all states\nobesity_data = brfss.get_obesity_data()\n\n# Display summary\nstats = brfss.summary(obesity_data)\nprint(f\"Year: {stats['year']}\")\nprint(f\"States: {stats['count']}\")\nprint(f\"Mean obesity rate: {stats['mean_value']:.1f}%\")\nprint(f\"Range: {stats['min_value']:.1f}% - {stats['max_value']:.1f}%\")\n</code></pre>"},{"location":"usage/brfss/#specific-year","title":"Specific Year","text":"<pre><code># Get 2022 obesity data\nobesity_2022 = brfss.get_obesity_data(year=2022)\n</code></pre>"},{"location":"usage/brfss/#generic-indicator-access","title":"Generic Indicator Access","text":"<p>Use <code>get_indicator()</code> to fetch any BRFSS health metric:</p> <pre><code># Physical inactivity\nphysical_inactivity = brfss.get_indicator(\n    class_name='Physical Activity',\n    question='Percent of adults aged 18 years and older who engage in no leisure-time physical activity'\n)\n\n# Fruit consumption\nfruit_consumption = brfss.get_indicator(\n    class_name='Fruits and Vegetables',\n    question='Percent of adults who report consuming fruit less than 1 time daily'\n)\n\n# Diabetes prevalence (if available in dataset)\ndiabetes = brfss.get_indicator(\n    class_name='Diabetes',\n    question='Percent of adults aged 18 years and older who have been told they have diabetes',\n    year=2022\n)\n</code></pre>"},{"location":"usage/brfss/#discovering-available-indicators","title":"Discovering Available Indicators","text":"<p>List all unique class/question combinations:</p> <pre><code>indicators = brfss.list_available_indicators()\nprint(f\"Total indicators: {len(indicators)}\")\nprint(indicators)\n\n# Filter by class\nobesity_indicators = indicators[indicators['class'] == 'Obesity / Weight Status']\nprint(obesity_indicators)\n</code></pre>"},{"location":"usage/brfss/#geographic-visualization","title":"Geographic Visualization","text":"<p>Create choropleth maps with Plotly:</p> <pre><code>import plotly.express as px\n\n# Get obesity data\nobesity_data = brfss.get_obesity_data()\n\n# Rename 'value' to 'obesity_rate' for clarity\nplot_data = obesity_data.rename(columns={'value': 'obesity_rate'})\n\n# Create map\nfig = px.choropleth(\n    plot_data,\n    locations='state',\n    locationmode='USA-states',\n    color='obesity_rate',\n    color_continuous_scale='YlOrRd',\n    range_color=(20, 40),\n    scope=\"usa\",\n    labels={'obesity_rate': 'Obesity Prevalence (%)'},\n    title=f\"Adult Obesity Prevalence by State ({plot_data['year'].iloc[0]})\",\n    hover_data={'state': True, 'state_name': True, 'obesity_rate': ':.1f'}\n)\nfig.show()\n</code></pre>"},{"location":"usage/brfss/#data-structure","title":"Data Structure","text":"<p>All BRFSS methods return DataFrames with standardized columns:</p> Column Type Description <code>year</code> int Survey year <code>state</code> str Two-letter state abbreviation <code>state_name</code> str Full state name <code>value</code> float Indicator value (e.g., prevalence percentage) <code>low_ci</code> float Lower 95% confidence interval <code>high_ci</code> float Upper 95% confidence interval <code>sample_size</code> int Sample size for estimate <code>data_source</code> str \"CDC BRFSS hn4x-zwk7\" <code>class_name</code> str BRFSS indicator class <code>question</code> str Full question text"},{"location":"usage/brfss/#caching","title":"Caching","text":"<p><code>BRFSSExplorer</code> uses in-memory caching to avoid repeated API calls:</p> <pre><code># First call fetches from API\nobesity_data = brfss.get_obesity_data()  # Network request\n\n# Second call uses cache\nobesity_data_cached = brfss.get_obesity_data()  # Instant\n\n# Disable caching\nbrfss_no_cache = BRFSSExplorer(enable_cache=False)\n</code></pre> <p>Cache keys are unique per indicator/year combination, so different indicators don't interfere:</p> <pre><code>obesity = brfss.get_obesity_data()  # Cached separately\nactivity = brfss.get_indicator(...)  # Different cache entry\n</code></pre>"},{"location":"usage/brfss/#error-handling","title":"Error Handling","text":"<p>Network failures and missing data return empty DataFrames with warnings:</p> <pre><code># Invalid year\ntry:\n    data = brfss.get_obesity_data(year=1999)  # Not in dataset\nexcept ValueError as e:\n    print(f\"Error: {e}\")  # \"Year 1999 not found...\"\n\n# Nonexistent indicator (returns empty DataFrame + warning)\ndata = brfss.get_indicator(\n    class_name='Nonexistent',\n    question='Invalid question'\n)\n# Prints: \"\u26a0 No data found for class='Nonexistent'...\"\nprint(data.empty)  # True\n</code></pre>"},{"location":"usage/brfss/#configuration","title":"Configuration","text":"<p>Customize API behavior with <code>BRFSSConfig</code>:</p> <pre><code>from pophealth_observatory.brfss import BRFSSExplorer, BRFSSConfig\n\nconfig = BRFSSConfig(\n    timeout=60,  # Longer timeout for slow connections\n    default_limit=10000  # Increase limit for future larger datasets\n)\n\nbrfss = BRFSSExplorer(config=config)\n</code></pre>"},{"location":"usage/brfss/#common-indicators","title":"Common Indicators","text":""},{"location":"usage/brfss/#obesity-weight-status","title":"Obesity &amp; Weight Status","text":"<ul> <li>\"Percent of adults aged 18 years and older who have obesity\"</li> <li>\"Percent of adults aged 18 years and older who are overweight\"</li> </ul>"},{"location":"usage/brfss/#physical-activity","title":"Physical Activity","text":"<ul> <li>\"Percent of adults aged 18 years and older who engage in no leisure-time physical activity\"</li> <li>\"Percent of adults meeting aerobic physical activity guidelines\"</li> <li>\"Percent of adults meeting muscle strengthening guidelines\"</li> </ul>"},{"location":"usage/brfss/#nutrition","title":"Nutrition","text":"<ul> <li>\"Percent of adults who report consuming fruit less than 1 time daily\"</li> <li>\"Percent of adults who report consuming vegetables less than 1 time daily\"</li> <li>\"Percent of adults who report drinking sugar-sweetened beverages at least 1 time daily\"</li> </ul>"},{"location":"usage/brfss/#chronic-conditions-if-available","title":"Chronic Conditions (if available)","text":"<ul> <li>\"Percent of adults aged 18 years and older who have been told they have diabetes\"</li> <li>\"Percent of adults ever told they have high blood pressure\"</li> </ul>"},{"location":"usage/brfss/#combining-nhanes-and-brfss","title":"Combining NHANES and BRFSS","text":"<p>National trends from NHANES + state-level patterns from BRFSS:</p> <pre><code>from pophealth_observatory import NHANESExplorer, BRFSSExplorer\n\n# National average from NHANES\nnhanes = NHANESExplorer()\nnhanes_data = nhanes.create_merged_dataset('2017-2018')\nnational_obesity = (nhanes_data['bmi'] &gt;= 30).mean() * 100\nprint(f\"National obesity rate (NHANES): {national_obesity:.1f}%\")\n\n# State-level from BRFSS\nbrfss = BRFSSExplorer()\nstate_obesity = brfss.get_obesity_data(year=2017)\nprint(f\"\\nState-level obesity rates (BRFSS {state_obesity['year'].iloc[0]}):\")\nprint(state_obesity[['state_name', 'value']].head())\n</code></pre>"},{"location":"usage/brfss/#api-reference","title":"API Reference","text":""},{"location":"usage/brfss/#brfssexplorer","title":"BRFSSExplorer","text":""},{"location":"usage/brfss/#methods","title":"Methods","text":"<ul> <li><code>get_obesity_data(year=None)</code></li> <li>Returns: DataFrame with state-level adult obesity prevalence</li> <li> <p>Parameters: <code>year</code> (int, optional) - specific year, defaults to latest</p> </li> <li> <p><code>get_indicator(class_name, question, year=None)</code></p> </li> <li>Returns: DataFrame for any BRFSS indicator</li> <li> <p>Parameters:</p> <ul> <li><code>class_name</code> (str) - BRFSS class (e.g., \"Physical Activity\")</li> <li><code>question</code> (str) - exact question text</li> <li><code>year</code> (int, optional) - specific year, defaults to latest</li> </ul> </li> <li> <p><code>list_available_indicators()</code></p> </li> <li>Returns: DataFrame with columns ['class', 'question']</li> <li> <p>Use to discover valid class/question combinations</p> </li> <li> <p><code>summary(df)</code></p> </li> <li>Returns: dict with count, mean, min, max, year, class, question</li> <li>Parameters: <code>df</code> - DataFrame from get_obesity_data() or get_indicator()</li> </ul>"},{"location":"usage/brfss/#data-source","title":"Data Source","text":"<ul> <li>Dataset: CDC BRFSS Nutrition, Physical Activity, and Obesity</li> <li>API: https://data.cdc.gov/resource/hn4x-zwk7.json</li> <li>Documentation: https://data.cdc.gov/Nutrition-Physical-Activity-and-Obesity</li> <li>Update Frequency: Annual</li> <li>Coverage: All 50 U.S. states + DC, territories (varies by year)</li> </ul>"},{"location":"usage/brfss/#limitations","title":"Limitations","text":"<ul> <li>Survey-based: Self-reported data (no clinical measurements)</li> <li>State-level only: No county or individual-level data</li> <li>Annual snapshots: Not continuous monitoring</li> <li>Variable availability: Not all indicators available for all years</li> <li>Question wording: Exact question text required for <code>get_indicator()</code></li> </ul>"},{"location":"usage/brfss/#best-practices","title":"Best Practices","text":"<ol> <li>Always check summary statistics before visualization to catch data issues</li> <li>Use list_available_indicators() to discover valid class/question pairs</li> <li>Enable caching (default) for interactive analysis</li> <li>Handle empty DataFrames gracefully (network failures, missing years)</li> <li>Document year in reports - BRFSS questions evolve over time</li> </ol>"},{"location":"usage/brfss/#examples","title":"Examples","text":"<p>See <code>notebooks/nhanes_explorer_demo.ipynb</code> Section 10 for complete geographic analysis workflow.</p>"},{"location":"usage/manifest/","title":"Manifest Reference","text":"<p>The manifest produced by <code>get_detailed_component_manifest</code> includes:</p> Key Description schema_version Version of manifest schema generated_at UTC ISO timestamp detailed_year_records Raw grouped rows per component summary_counts Aggregated counts by component &amp; file type component_count Number of component pages processed total_file_rows Row count after filtering dataframe (optional) Flattened DataFrame if requested"},{"location":"usage/manifest/#filtering-logic","title":"Filtering Logic","text":"<ul> <li>Year range keeps rows whose interval overlaps the requested span.</li> <li>File types are matched against upper-cased set (e.g. <code>XPT</code>, <code>ZIP</code>).</li> </ul>"},{"location":"usage/manifest/#example","title":"Example","text":"<pre><code>m = exp.get_detailed_component_manifest(as_dataframe=True,\n                                        file_types=[\"XPT\"],\n                                        year_range=(\"2015\",\"2022\"))\nprint(m['total_file_rows'])\n</code></pre>"},{"location":"usage/quickstart/","title":"Quick Start","text":"<pre><code>from pophealth_observatory.observatory import NHANESExplorer\nexp = NHANESExplorer()\nmerged = exp.create_merged_dataset('2017-2018')\nprint(merged.head())\n</code></pre>"},{"location":"usage/quickstart/#generate-manifest-xpt-only-2017-2022","title":"Generate Manifest (XPT only, 2017-2022)","text":"<pre><code>manifest = exp.get_detailed_component_manifest(\n    as_dataframe=True,\n    year_range=(\"2017\",\"2022\"),\n    file_types=[\"XPT\"],\n)\nprint(manifest['summary_counts'])\n</code></pre>"},{"location":"usage/validation/","title":"Data Validation","text":"<p>PopHealth Observatory includes a comprehensive programmatic validation system that verifies downloaded NHANES data against official CDC metadata sources. This provides confidence in data integrity and completeness, essential for research and production use.</p>"},{"location":"usage/validation/#overview","title":"Overview","text":"<p>The validation module automatically:</p> <ol> <li>Verifies URLs - Confirms that data file URLs match CDC's official documentation</li> <li>Checks Row Counts - Validates that downloaded data contains the expected number of records</li> <li>Generates Reports - Produces structured validation reports with PASS/WARN/FAIL status</li> </ol>"},{"location":"usage/validation/#quick-start","title":"Quick Start","text":"<pre><code>from pophealth_observatory import NHANESExplorer\n\n# Initialize explorer\nexplorer = NHANESExplorer()\n\n# Validate specific components for a cycle\nreport = explorer.validate(\n    cycle='2017-2018',\n    components=['demographics', 'body_measures']\n)\n\n# Check overall status\nprint(f\"Validation Status: {report['status']}\")  # PASS, WARN, or FAIL\n\n# Review detailed results\nfor component, details in report['components'].items():\n    print(f\"\\n{component}: {details['status']}\")\n    for check_name, check_result in details['checks'].items():\n        print(f\"  {check_name}: {check_result['status']}\")\n        print(f\"    {check_result['details']}\")\n</code></pre>"},{"location":"usage/validation/#validation-report-structure","title":"Validation Report Structure","text":"<p>The validation report is a nested dictionary with the following structure:</p> <pre><code>{\n    'cycle': '2017-2018',\n    'status': 'PASS',  # Overall status\n    'components': {\n        'demographics': {\n            'status': 'PASS',\n            'checks': {\n                'url_pattern_match': {\n                    'status': 'PASS',\n                    'details': 'Generated URL pattern matches CDC official URL',\n                    'expected': 'https://wwwn.cdc.gov/.../DEMO_J.XPT',\n                    'actual': 'DEMO_J.XPT'\n                },\n                'row_count': {\n                    'status': 'PASS',\n                    'details': 'Downloaded 9254 rows, matches expected count',\n                    'expected': 9254,\n                    'actual': 9254\n                }\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"usage/validation/#status-values","title":"Status Values","text":"<ul> <li>PASS: All validation checks passed successfully</li> <li>WARN: Minor issues detected (e.g., could not parse metadata, but data appears correct)</li> <li>FAIL: Critical issues detected (e.g., row count mismatch, incorrect URL)</li> </ul>"},{"location":"usage/validation/#use-cases","title":"Use Cases","text":""},{"location":"usage/validation/#pre-analysis-validation","title":"Pre-Analysis Validation","text":"<p>Validate data before running analysis to ensure data quality:</p> <pre><code>explorer = NHANESExplorer()\n\n# Validate before analysis\nreport = explorer.validate('2017-2018', ['demographics', 'body_measures'])\n\nif report['status'] == 'PASS':\n    # Safe to proceed with analysis\n    data = explorer.get_merged_data('2017-2018')\n    # ... perform analysis ...\nelse:\n    print(\"Validation failed! Review report before proceeding.\")\n    print(report)\n</code></pre>"},{"location":"usage/validation/#cicd-integration","title":"CI/CD Integration","text":"<p>Include validation in automated testing pipelines:</p> <pre><code>import pytest\nfrom pophealth_observatory import NHANESExplorer\n\ndef test_nhanes_data_integrity():\n    \"\"\"Ensure NHANES data downloads are valid.\"\"\"\n    explorer = NHANESExplorer()\n    report = explorer.validate('2017-2018', ['demographics'])\n    assert report['status'] in ['PASS', 'WARN'], f\"Validation failed: {report}\"\n</code></pre>"},{"location":"usage/validation/#demo-preparation","title":"Demo Preparation","text":"<p>Verify data correctness before demonstrations or presentations:</p> <pre><code># Validate your demo use case\nexplorer = NHANESExplorer()\nreport = explorer.validate('2017-2018', ['demographics', 'body_measures'])\n\n# Generate validation summary\nprint(f\"Validation Report: {report['cycle']}\")\nprint(f\"Overall Status: {report['status']}\")\n\nfor component in report['components']:\n    comp_status = report['components'][component]['status']\n    print(f\"  {component}: {comp_status}\")\n</code></pre>"},{"location":"usage/validation/#behind-the-scenes","title":"Behind the Scenes","text":"<p>The validation system:</p> <ol> <li>Scrapes CDC Pages: Uses BeautifulSoup to parse official NHANES component documentation pages</li> <li>Extracts Metadata: Parses record counts and data file URLs from CDC HTML</li> <li>Compares Results: Downloads data using the explorer and compares against CDC metadata</li> <li>Reports Findings: Structures results with clear PASS/WARN/FAIL status</li> </ol>"},{"location":"usage/validation/#handling-validation-failures","title":"Handling Validation Failures","text":""},{"location":"usage/validation/#row-count-mismatch","title":"Row Count Mismatch","text":"<p>If row counts don't match:</p> <pre><code># Check the specific mismatch\nrow_check = report['components']['demographics']['checks']['row_count']\nprint(f\"Expected: {row_check['expected']}\")\nprint(f\"Actual: {row_check['actual']}\")\n\n# Possible causes:\n# - Network interruption during download\n# - CDC updated the dataset\n# - Explorer URL resolution issue\n</code></pre> <p>Resolution: - Clear cache and retry download - Verify cycle and component names - Check CDC website for dataset updates</p>"},{"location":"usage/validation/#url-pattern-mismatch","title":"URL Pattern Mismatch","text":"<p>If URLs don't match:</p> <pre><code>url_check = report['components']['demographics']['checks']['url_pattern_match']\nprint(f\"Expected: {url_check['expected']}\")\nprint(f\"Actual: {url_check['actual']}\")\n</code></pre> <p>Resolution: - Verify cycle suffix mapping in <code>explorer.cycle_suffix_map</code> - Check if CDC changed URL structure - Review component code in <code>explorer.components</code></p>"},{"location":"usage/validation/#network-errors","title":"Network Errors","text":"<p>If CDC pages cannot be accessed:</p> <pre><code># Look for scraping errors\nif 'cdc_scrape' in report['components']['demographics']['checks']:\n    scrape_check = report['components']['demographics']['checks']['cdc_scrape']\n    if scrape_check['status'] == 'FAIL':\n        print(f\"Network issue: {scrape_check['details']}\")\n</code></pre> <p>Resolution: - Check internet connectivity - Verify CDC website is accessible - Retry after a short delay</p>"},{"location":"usage/validation/#advanced-usage","title":"Advanced Usage","text":""},{"location":"usage/validation/#custom-validation-logic","title":"Custom Validation Logic","text":"<p>Extend validation for custom checks:</p> <pre><code>from pophealth_observatory.validation import validate_component\n\n# Run validation for a single component\ncomp_validation = validate_component(\n    explorer=explorer,\n    cycle='2017-2018',\n    component='demographics'\n)\n\n# Access individual checks\nfor check in comp_validation.checks:\n    print(f\"{check.name}: {check.status}\")\n    if check.status == 'FAIL':\n        print(f\"  Issue: {check.details}\")\n        print(f\"  Expected: {check.expected}\")\n        print(f\"  Actual: {check.actual}\")\n</code></pre>"},{"location":"usage/validation/#batch-validation","title":"Batch Validation","text":"<p>Validate multiple cycles:</p> <pre><code>cycles = ['2015-2016', '2017-2018', '2019-2020']\ncomponents = ['demographics', 'body_measures']\n\nresults = {}\nfor cycle in cycles:\n    report = explorer.validate(cycle, components)\n    results[cycle] = report['status']\n\nprint(\"Validation Summary:\")\nfor cycle, status in results.items():\n    print(f\"  {cycle}: {status}\")\n</code></pre>"},{"location":"usage/validation/#technical-details","title":"Technical Details","text":""},{"location":"usage/validation/#data-classes","title":"Data Classes","text":"<p>The validation module uses dataclasses for structured results:</p> <ul> <li><code>ValidationCheck</code>: Single check result (name, status, details, expected, actual)</li> <li><code>ComponentValidation</code>: All checks for one component</li> <li><code>ValidationReport</code>: Complete report for a cycle</li> </ul>"},{"location":"usage/validation/#http-scraping","title":"HTTP Scraping","text":"<ul> <li>Uses <code>requests</code> for HTTP GET with 10-second timeout</li> <li>Parses HTML with <code>BeautifulSoup</code> (lxml parser)</li> <li>Extracts record counts via regex patterns</li> <li>Handles both absolute and relative CDC URLs</li> </ul>"},{"location":"usage/validation/#error-handling","title":"Error Handling","text":"<ul> <li>Network errors return FAIL status with error message</li> <li>Parsing failures return WARN status</li> <li>Missing metadata returns WARN (graceful degradation)</li> </ul>"},{"location":"usage/validation/#best-practices","title":"Best Practices","text":"<ol> <li>Always validate before critical analysis - Ensures data integrity</li> <li>Review WARN status carefully - May indicate partial data or parsing issues</li> <li>Cache validation results - Avoid repeated CDC page scraping</li> <li>Include in test suites - Catch data issues early in development</li> <li>Document validation outcomes - Include in research methods/notes</li> </ol>"},{"location":"usage/validation/#future-enhancements","title":"Future Enhancements","text":"<p>Planned improvements:</p> <ul> <li>Column-level validation (verify expected columns exist)</li> <li>Data type validation (ensure numeric fields are numeric)</li> <li>Range validation (check values within expected ranges)</li> <li>Cross-component consistency checks</li> <li>Historical validation result tracking</li> </ul>"},{"location":"usage/validation/#support","title":"Support","text":"<p>If validation consistently fails for known-good cycles/components:</p> <ol> <li>Verify dependencies installed: <code>pip install beautifulsoup4 lxml</code></li> <li>Check CDC website accessibility</li> <li>Review GitHub Issues</li> <li>File a bug report with validation report output</li> </ol> <p>Related Documentation: - Getting Started - Basic usage - API Reference - Full API documentation - Usage Examples - More code examples</p>"}]}